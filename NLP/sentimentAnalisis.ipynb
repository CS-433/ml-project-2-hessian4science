{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from utils import HATEDataset, train, preprocess\n",
    "from models import SentimentBaselineModel, VanillaLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "seed = 366767\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "data = pd.read_csv(\"labeled_data.csv\")\n",
    "data = data[['class', 'tweet']]\n",
    "tweet = list(data['tweet'])\n",
    "\n",
    "#Data cleaning\n",
    "clean_tweet = preprocess(tweet)\n",
    "data['tweet'] = clean_tweet\n",
    "\n",
    "#Split data\n",
    "train_data = data[:int(len(data)*0.8)]\n",
    "test_data = data[int(len(data)*0.8):]\n",
    "\n",
    "#Create new CSV\n",
    "train_data.to_csv(\"train.csv\", index=False)\n",
    "test_data.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "\n",
    "#Data imbalance\n",
    "series = train_data['class'].value_counts().sort_index() / len(train_data)\n",
    "train_count = torch.tensor(series).float().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training params\n",
    "device = torch.device('cuda:0') \n",
    "\n",
    "# We use the following pretrained tokenizer and model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=3).to(device)\n",
    "\n",
    "train_dataset = HATEDataset(\"train.csv\", tokenizer)\n",
    "test_dataset = HATEDataset(\"test.csv\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "max_grad_norm = 1.0\n",
    "warmup_percent = 0.1\n",
    "learning_rate = 5e-3\n",
    "\n",
    "train(train_dataset, test_dataset, model, device, batch_size, epochs, learning_rate, warmup_percent, max_grad_norm, train_count)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
